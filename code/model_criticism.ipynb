{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is a Python exploration of this R-based document: http://m-clark.github.io/data-processing-and-visualization/.  It is intended for those new to modeling and related concepts.  Code is *not* optimized for anything but learning.  In addition, all the content is located with the main document, not here, so many sections may not be included.  I only focus on reproducing the code chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Criticism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "happy = pd.read_csv('../data/world_hapiness.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_model_base = smf.ols(\n",
    "  'happiness_score ~ democratic_quality + generosity + log_gdp_per_capita',\n",
    "  data = happy\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical\n",
    "\n",
    "In a standard linear model we can compare a model where there are no covariates vs. the model we actually care about, which may have many predictor variables.  This is an almost useless test, but the results are typically reported both in standard output and academic presentation.  Let's think about it conceptually- how does the variability in our target break down?\n",
    "\n",
    "<br>\n",
    "$$\\textrm{Total Variance} = \\textrm{Model Explained Variance} + \\textrm{Residual Variance}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the variability in our target (TV) can be decomposed into that which we can explain with the predictor variables (MEV), and everything else that is not in our model (RV). If we have nothing in the model, then TV = RV.\n",
    "\n",
    "Let's revisit the summary of our model.  Note the *F-statistic*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>happiness_score</td> <th>  R-squared:         </th> <td>   0.695</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.693</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   309.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 25 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>1.24e-104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:33:05</td>     <th>  Log-Likelihood:    </th> <td> -390.15</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   411</td>      <th>  AIC:               </th> <td>   788.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   407</td>      <th>  BIC:               </th> <td>   804.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>   -1.0105</td> <td>    0.314</td> <td>   -3.214</td> <td> 0.001</td> <td>   -1.628</td> <td>   -0.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>democratic_quality</th> <td>    0.1704</td> <td>    0.046</td> <td>    3.714</td> <td> 0.000</td> <td>    0.080</td> <td>    0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>generosity</th>         <td>    1.1608</td> <td>    0.195</td> <td>    5.938</td> <td> 0.000</td> <td>    0.777</td> <td>    1.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_gdp_per_capita</th> <td>    0.6934</td> <td>    0.033</td> <td>   20.792</td> <td> 0.000</td> <td>    0.628</td> <td>    0.759</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.428</td> <th>  Durbin-Watson:     </th> <td>   0.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.180</td> <th>  Jarque-Bera (JB):  </th> <td>   2.731</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.075</td> <th>  Prob(JB):          </th> <td>   0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.630</td> <th>  Cond. No.          </th> <td>    96.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        happiness_score   R-squared:                       0.695\n",
       "Model:                            OLS   Adj. R-squared:                  0.693\n",
       "Method:                 Least Squares   F-statistic:                     309.6\n",
       "Date:                Tue, 25 Feb 2020   Prob (F-statistic):          1.24e-104\n",
       "Time:                        14:33:05   Log-Likelihood:                -390.15\n",
       "No. Observations:                 411   AIC:                             788.3\n",
       "Df Residuals:                     407   BIC:                             804.4\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept             -1.0105      0.314     -3.214      0.001      -1.628      -0.393\n",
       "democratic_quality     0.1704      0.046      3.714      0.000       0.080       0.261\n",
       "generosity             1.1608      0.195      5.938      0.000       0.777       1.545\n",
       "log_gdp_per_capita     0.6934      0.033     20.792      0.000       0.628       0.759\n",
       "==============================================================================\n",
       "Omnibus:                        3.428   Durbin-Watson:                   0.809\n",
       "Prob(Omnibus):                  0.180   Jarque-Bera (JB):                2.731\n",
       "Skew:                           0.075   Prob(JB):                        0.255\n",
       "Kurtosis:                       2.630   Cond. No.                         96.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_model_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard F statistic can be calculated as follows, where $p$ is the number of predictors:\n",
    "\n",
    "$$F = \\frac{MV/p}{RV/(N-p-1)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually it is a ratio of average squared variance to average unexplained variance. We can see this more explicitly as follows, where each predictor's contribution to the total variance is provided in the `sum_sq` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>democratic_quality</td>\n",
       "      <td>1.0</td>\n",
       "      <td>189.191976</td>\n",
       "      <td>189.191976</td>\n",
       "      <td>479.300218</td>\n",
       "      <td>8.896592e-71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>generosity</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.774203</td>\n",
       "      <td>6.774203</td>\n",
       "      <td>17.161811</td>\n",
       "      <td>4.176867e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>log_gdp_per_capita</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170.649392</td>\n",
       "      <td>170.649392</td>\n",
       "      <td>432.324313</td>\n",
       "      <td>5.925015e-66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Residual</td>\n",
       "      <td>407.0</td>\n",
       "      <td>160.653242</td>\n",
       "      <td>0.394725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       df      sum_sq     mean_sq           F        PR(>F)\n",
       "democratic_quality    1.0  189.191976  189.191976  479.300218  8.896592e-71\n",
       "generosity            1.0    6.774203    6.774203   17.161811  4.176867e-05\n",
       "log_gdp_per_capita    1.0  170.649392  170.649392  432.324313  5.925015e-66\n",
       "Residual            407.0  160.653242    0.394725         NaN           NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.stats.anova_lm(happy_model_base) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add those together and use our formula above we get:\n",
    "\n",
    "$$F = \\frac{366.62/3}{160.653/407} = 309.6$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is what is reported in the summary of the model. And these values can be extracted from the summary object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.241861773180128e-104"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_model_base.fvalue\n",
    "happy_model_base.f_pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the F-value is so large and p-value so small, we can demonstrate this more clearly with a worse model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test = smf.ols('happiness_score ~ generosity', data = happy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>happiness_score</td> <th>  R-squared:         </th> <td>   0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 25 Feb 2020</td> <th>  Prob (F-statistic):</th>  <td>0.00318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:33:05</td>     <th>  Log-Likelihood:    </th> <td> -819.50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   535</td>      <th>  AIC:               </th> <td>   1643.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   533</td>      <th>  BIC:               </th> <td>   1652.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>    5.4190</td> <td>    0.049</td> <td>  111.692</td> <td> 0.000</td> <td>    5.324</td> <td>    5.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>generosity</th> <td>    0.8994</td> <td>    0.304</td> <td>    2.963</td> <td> 0.003</td> <td>    0.303</td> <td>    1.496</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>77.072</td> <th>  Durbin-Watson:     </th> <td>   0.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  19.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.018</td> <th>  Prob(JB):          </th> <td>6.28e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.069</td> <th>  Cond. No.          </th> <td>    6.26</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        happiness_score   R-squared:                       0.016\n",
       "Model:                            OLS   Adj. R-squared:                  0.014\n",
       "Method:                 Least Squares   F-statistic:                     8.780\n",
       "Date:                Tue, 25 Feb 2020   Prob (F-statistic):            0.00318\n",
       "Time:                        14:33:05   Log-Likelihood:                -819.50\n",
       "No. Observations:                 535   AIC:                             1643.\n",
       "Df Residuals:                     533   BIC:                             1652.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      5.4190      0.049    111.692      0.000       5.324       5.514\n",
       "generosity     0.8994      0.304      2.963      0.003       0.303       1.496\n",
       "==============================================================================\n",
       "Omnibus:                       77.072   Durbin-Watson:                   0.582\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               19.350\n",
       "Skew:                          -0.018   Prob(JB):                     6.28e-05\n",
       "Kurtosis:                       2.069   Cond. No.                         6.26\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_test.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0031808086892723964"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "1 - f.cdf(8.780433, 1, 533)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistical result just shown is mostly a straw man type of test- who actually cares if our model does statistically better than a model with nothing in it?  Surely if you don't do better than nothing, then you may need to think more intently about what you are trying to model and how.  But just because you can knock the straw man down, it isn't something to get overly excited about. Let's turn instead to a different concept- the amount of variance of the target variable that is explained by our predictors.  For the standard linear model setting, this statistic is called *R-squared* ($R^2$).\n",
    "\n",
    "Going back to our previous notions, $R^2$ is just:\n",
    "\n",
    "$$R^2 =\\textrm{Model Explained Variance}/\\textrm{Total Variance}$$\n",
    "\n",
    "This too is reported by default in our summary printout, or extract it from the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6953105544830919"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_model_base.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our values from before for model and total variance, we can calculate it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6953173895727047"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "366.62 / 527.27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another way.  Let's get the model predictions, and see how well they correlate with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8338528374258207\n",
      "0.6953105544830922\n"
     ]
    }
   ],
   "source": [
    "predictions = happy_model_base.fittedvalues\n",
    "target = happy_model_base.model.endog  # \n",
    "rho = np.corrcoef(predictions, target)\n",
    "print(rho[0,1])\n",
    "print(rho[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with $R^2$ is that it always goes up, no matter what nonsense you add to a model.  This is why we have an *adjusted $R^2$* that attempts to balance the sample size and model complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6930646863343186"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_model_base.rsquared_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical targets we must think about obtaining predictions that allow us to classify the observations into specific categories.  Not surprisingly, this will require different metrics to assess model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and other metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very natural starting point is *accuracy*, or what percentage of our predicted class labels match the observed class labels.  However, our model will not spit out a character string, only a number. On the scale of the linear predictor it can be anything, but we will at some point transform it to the probability scale, obtaining a predicted probability for each category.  The class associated with the highest probability is the predicted class.  In the case of binary targets, this is just an <span class=\"func\" style = \"\">if_else</span> statement for one class `'class A' if (probability >= .5) else 'class B'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With those predicted labels and the observed labels we create what is commonly called a *confusion matrix*, but would more sanely be called a *classification table*, *prediction table*, or just about any other name one could come up with in the first 10 seconds of trying.  Let's look at the following hypothetical result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observed 1</th>\n",
       "      <th>Observed 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Predicted 1</td>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Predicted 0</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Observed 1  Observed 0\n",
       "Predicted 1          41          21\n",
       "Predicted 0          16          13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Observed 1': [41, 16], \n",
    "              'Observed 0': [21, 13]}, \n",
    "             index = ['Predicted 1', 'Predicted 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observed 1</th>\n",
       "      <th>Observed 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Predicted 1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Predicted 0</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Observed 1 Observed 0\n",
       "Predicted 1          A          B\n",
       "Predicted 0          C          D"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Observed 1': ['A', 'C'], \n",
    "              'Observed 0': ['B', 'D']}, \n",
    "             index = ['Predicted 1', 'Predicted 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases we predict correctly, in other cases not.  In this 2 x 2 setting we label the cells A through D.  With things in place, consider the following the following nomenclature.\n",
    "\n",
    "*True Positive*, *False Positive*, *True Negative*, *False Negative*: Above, these are A, B, D, and C respectively.\n",
    "\n",
    "Now let's see what we can calculate.\n",
    "\n",
    "*Accuracy*: Number of correct classifications out of all predictions (A + D)/Total. In the above example this would be (41 + 13)/91.\n",
    "\n",
    "*Error Rate*: 1 - Accuracy.\n",
    "\n",
    "*Sensitivity*: is the proportion of correctly predicted positives to all true positive events: A/(A + C).  In the above example this would be 41/57. High sensitivity would suggest a low type II error rate (see below), or high statistical power. Also known as *true positive rate*.\n",
    "\n",
    "*Specificity*: is the proportion of correctly predicted negatives to all true negative events: D/(B + D).  In the above example this would be 13/34. High specificity would suggest a low type I error rate (see below). Also known as *true negative rate*.\n",
    "\n",
    "*Positive Predictive Value* (PPV): proportion of true positives of those that are predicted positives: A/(A + B). In the above example this would be 41/62.\n",
    "\n",
    "*Negative Predictive Value* (NPV): proportion of true negatives of those that are predicted negative: D/(C + D). In the above example this would be 13/29.\n",
    "\n",
    "*Precision*:  See PPV.\n",
    "\n",
    "*Recall*: See sensitivity.\n",
    "\n",
    "*Lift*: Ratio of positive predictions given actual positives to the proportion of positive predictions out of the total: (A/(A + C)) / ((A + B)/Total). In the above example this would be (41/(41 + 16))/((41 + 21)/(91)).\n",
    "\n",
    "*F Score* (F1 score): Harmonic mean of precision and recall: 2\\*(Precision\\*Recall)/(Precision+Recall). In the above example this would be 2\\*(.66\\*.72)/(.66+.72).\n",
    "\n",
    "*Type I Error Rate* (false positive rate): proportion of true negatives that are incorrectly predicted positive: B/(B+D). In the above example this would be 21/34.  Also known as *alpha*.\n",
    "\n",
    "*Type II Error Rate* (false negative rate): proportion of true positives that are incorrectly predicted negative: C/(C+A). In the above example this would be 16/57. Also known as *beta*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many others. See the [pycm module](https://github.com/sepandhaghighi/pycm) for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few assumptions for the standard linear model that we could talk about, but I'll focus on just a handful, ordered roughly in terms of the severity of violation. \n",
    "\n",
    "- Correct model\n",
    "- Heteroscedasticity\n",
    "- Independence of observations\n",
    "- Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually showed some of this before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "sm.graphics.plot_regress_exog(happy_model_base, 'generosity', fig = fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect a histogram of the residuals to check for normality.  Here I use seaborn as a nice way to get the density overlay of the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe1b0d07b50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(\n",
    "    happy_model_base.resid, \n",
    "    hist = True, \n",
    "    kde = True,\n",
    "    bins = int(180/5), \n",
    "    color = 'darkblue', \n",
    "    hist_kws = {'edgecolor':'black'},\n",
    "    kde_kws={'linewidth': 4}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y =  happy_model_base.model.exog, happy_model_base.model.endog\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size = 0.33, \n",
    "    random_state = 1212\n",
    ")\n",
    "X_train\n",
    "\n",
    "happy_model_train = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "predictions = happy_model_train.predict(exog = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing our loss on training and test (i.e. RMSE), we can see the loss is greater on the test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.631502</td>\n",
       "      <td>0.615318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RMSE_train  RMSE_test\n",
       "0    0.631502   0.615318"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'by-hand' calculations\n",
    "RMSE_train = np.sqrt(happy_model_train.resid.dot(happy_model_train.resid)/happy_model_train.nobs)\n",
    "RMSE_test = np.sqrt(sum((predictions - y_test)**2)/y_test.shape[0])\n",
    "\n",
    "pd.DataFrame({'RMSE_train': RMSE_train, 'RMSE_test': RMSE_test}, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.631502</td>\n",
       "      <td>0.615318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RMSE_train  RMSE_test\n",
       "0    0.631502   0.615318"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # alternative\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "pd.DataFrame({\n",
    "    'RMSE_train': np.sqrt(mean_squared_error(happy_model_train.fittedvalues, y_train)),\n",
    "    'RMSE_test': np.sqrt(mean_squared_error(predictions, y_test))}, \n",
    "    index = [0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Additional covariates\n",
    "\n",
    "A starting point for adding model complexity is simply adding more covariates.  Let's add life expectancy and a yearly trend to our happiness model.  To make this model comparable to our baseline model, they need to be fit to the same data, and life expectancy has a couple missing values the others do not.  So we'll start with some data processing. I will start by standardizing some of the variables, and making year start at zero, which will represent 2008, and finally dropping missing values.  Refer to our previous section on transforming variables if you want to.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>happiness_score</th>\n",
       "      <th>democratic_quality</th>\n",
       "      <th>generosity</th>\n",
       "      <th>healthy_life_expectancy_at_birth</th>\n",
       "      <th>log_gdp_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.625550</td>\n",
       "      <td>-1.950587</td>\n",
       "      <td>0.545034</td>\n",
       "      <td>-1.307413</td>\n",
       "      <td>7.500539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>11</td>\n",
       "      <td>-1.815967</td>\n",
       "      <td>-1.963219</td>\n",
       "      <td>0.314034</td>\n",
       "      <td>-1.333794</td>\n",
       "      <td>7.497038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.431590</td>\n",
       "      <td>-1.998775</td>\n",
       "      <td>-0.687488</td>\n",
       "      <td>-1.360174</td>\n",
       "      <td>7.497755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Albania</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.399795</td>\n",
       "      <td>0.442664</td>\n",
       "      <td>-0.517345</td>\n",
       "      <td>0.618363</td>\n",
       "      <td>9.302960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Albania</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.669036</td>\n",
       "      <td>0.449130</td>\n",
       "      <td>-0.127154</td>\n",
       "      <td>0.657933</td>\n",
       "      <td>9.337532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country  year  happiness_score  democratic_quality  generosity  \\\n",
       "7   Afghanistan    10        -1.625550           -1.950587    0.545034   \n",
       "8   Afghanistan    11        -1.815967           -1.963219    0.314034   \n",
       "9   Afghanistan    12        -1.431590           -1.998775   -0.687488   \n",
       "18      Albania    10        -0.399795            0.442664   -0.517345   \n",
       "19      Albania    11        -0.669036            0.449130   -0.127154   \n",
       "\n",
       "    healthy_life_expectancy_at_birth  log_gdp_per_capita  \n",
       "7                          -1.307413            7.500539  \n",
       "8                          -1.333794            7.497038  \n",
       "9                          -1.360174            7.497755  \n",
       "18                          0.618363            9.302960  \n",
       "19                          0.657933            9.337532  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale(x):\n",
    "    return((x - np.nanmean(x, axis=0))/np.nanstd(x, axis=0))\n",
    "\n",
    "happy_processed = happy[[\n",
    "    'country', \n",
    "    'year', \n",
    "    'happiness_score',\n",
    "    'democratic_quality',\n",
    "    'generosity',\n",
    "    'healthy_life_expectancy_at_birth',\n",
    "    'log_gdp_per_capita'\n",
    "]].apply(\n",
    "    lambda x: scale(x)\n",
    "    if x.name in [\n",
    "        'happiness_score',\n",
    "        'democratic_quality',\n",
    "        'generosity',\n",
    "        'healthy_life_expectancy_at_birth',] \n",
    "    else x\n",
    ").assign(\n",
    "    year = happy.year - np.min(happy.year)\n",
    ").dropna()\n",
    "\n",
    "happy_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start with our baseline model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>happiness_score</td> <th>  R-squared:         </th> <td>   0.695</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.693</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   307.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 25 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>4.51e-104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:33:07</td>     <th>  Log-Likelihood:    </th> <td> -339.33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   409</td>      <th>  AIC:               </th> <td>   686.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   405</td>      <th>  BIC:               </th> <td>   702.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>   -5.7037</td> <td>    0.276</td> <td>  -20.701</td> <td> 0.000</td> <td>   -6.245</td> <td>   -5.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>democratic_quality</th> <td>    0.1348</td> <td>    0.036</td> <td>    3.760</td> <td> 0.000</td> <td>    0.064</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>generosity</th>         <td>    0.1689</td> <td>    0.028</td> <td>    5.955</td> <td> 0.000</td> <td>    0.113</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_gdp_per_capita</th> <td>    0.6136</td> <td>    0.030</td> <td>   20.729</td> <td> 0.000</td> <td>    0.555</td> <td>    0.672</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.562</td> <th>  Durbin-Watson:     </th> <td>   0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.169</td> <th>  Jarque-Bera (JB):  </th> <td>   2.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.082</td> <th>  Prob(JB):          </th> <td>   0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.626</td> <th>  Cond. No.          </th> <td>    95.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        happiness_score   R-squared:                       0.695\n",
       "Model:                            OLS   Adj. R-squared:                  0.693\n",
       "Method:                 Least Squares   F-statistic:                     307.8\n",
       "Date:                Tue, 25 Feb 2020   Prob (F-statistic):          4.51e-104\n",
       "Time:                        14:33:07   Log-Likelihood:                -339.33\n",
       "No. Observations:                 409   AIC:                             686.7\n",
       "Df Residuals:                     405   BIC:                             702.7\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept             -5.7037      0.276    -20.701      0.000      -6.245      -5.162\n",
       "democratic_quality     0.1348      0.036      3.760      0.000       0.064       0.205\n",
       "generosity             0.1689      0.028      5.955      0.000       0.113       0.225\n",
       "log_gdp_per_capita     0.6136      0.030     20.729      0.000       0.555       0.672\n",
       "==============================================================================\n",
       "Omnibus:                        3.562   Durbin-Watson:                   0.808\n",
       "Prob(Omnibus):                  0.169   Jarque-Bera (JB):                2.837\n",
       "Skew:                           0.082   Prob(JB):                        0.242\n",
       "Kurtosis:                       2.626   Cond. No.                         95.0\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_model_base = smf.ols(\n",
    "  'happiness_score ~ democratic_quality + generosity + log_gdp_per_capita',\n",
    "  data = happy_processed\n",
    ").fit()\n",
    "\n",
    "happy_model_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that moving one standard deviation on democratic quality and generosity leads to similar standard deviation increases in happiness.  Moving 10 percentage points in GDP would lead to less than .1 standard deviation increase in happiness.\n",
    "\n",
    "Now we add our life expectancy and yearly trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>happiness_score</td> <th>  R-squared:         </th> <td>   0.727</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.724</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   214.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 25 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>3.19e-111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:33:07</td>     <th>  Log-Likelihood:    </th> <td> -316.73</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   409</td>      <th>  AIC:               </th> <td>   645.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   403</td>      <th>  BIC:               </th> <td>   669.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                        <td>   -3.5944</td> <td>    0.532</td> <td>   -6.762</td> <td> 0.000</td> <td>   -4.639</td> <td>   -2.549</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>democratic_quality</th>               <td>    0.0668</td> <td>    0.035</td> <td>    1.887</td> <td> 0.060</td> <td>   -0.003</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>generosity</th>                       <td>    0.1648</td> <td>    0.027</td> <td>    6.109</td> <td> 0.000</td> <td>    0.112</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_gdp_per_capita</th>               <td>    0.3945</td> <td>    0.043</td> <td>    9.277</td> <td> 0.000</td> <td>    0.311</td> <td>    0.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>healthy_life_expectancy_at_birth</th> <td>    0.3871</td> <td>    0.056</td> <td>    6.860</td> <td> 0.000</td> <td>    0.276</td> <td>    0.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>                             <td>   -0.0113</td> <td>    0.032</td> <td>   -0.352</td> <td> 0.725</td> <td>   -0.074</td> <td>    0.052</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.277</td> <th>  Durbin-Watson:     </th> <td>   0.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.026</td> <th>  Jarque-Bera (JB):  </th> <td>   4.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.009</td> <th>  Prob(JB):          </th> <td>   0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.492</td> <th>  Cond. No.          </th> <td>    296.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        happiness_score   R-squared:                       0.727\n",
       "Model:                            OLS   Adj. R-squared:                  0.724\n",
       "Method:                 Least Squares   F-statistic:                     214.7\n",
       "Date:                Tue, 25 Feb 2020   Prob (F-statistic):          3.19e-111\n",
       "Time:                        14:33:07   Log-Likelihood:                -316.73\n",
       "No. Observations:                 409   AIC:                             645.5\n",
       "Df Residuals:                     403   BIC:                             669.6\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================\n",
       "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------\n",
       "Intercept                           -3.5944      0.532     -6.762      0.000      -4.639      -2.549\n",
       "democratic_quality                   0.0668      0.035      1.887      0.060      -0.003       0.136\n",
       "generosity                           0.1648      0.027      6.109      0.000       0.112       0.218\n",
       "log_gdp_per_capita                   0.3945      0.043      9.277      0.000       0.311       0.478\n",
       "healthy_life_expectancy_at_birth     0.3871      0.056      6.860      0.000       0.276       0.498\n",
       "year                                -0.0113      0.032     -0.352      0.725      -0.074       0.052\n",
       "==============================================================================\n",
       "Omnibus:                        7.277   Durbin-Watson:                   0.834\n",
       "Prob(Omnibus):                  0.026   Jarque-Bera (JB):                4.407\n",
       "Skew:                           0.009   Prob(JB):                        0.110\n",
       "Kurtosis:                       2.492   Cond. No.                         296.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_model_more = smf.ols(\n",
    "  'happiness_score ~ democratic_quality + generosity + log_gdp_per_capita + healthy_life_expectancy_at_birth + year',\n",
    "  data = happy_processed\n",
    ").fit()\n",
    "\n",
    "happy_model_more.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it would seem that life expectancy has a notable effect on happiness (shocker), but the yearly trend, while negative, is not statistically notable.  In addition, the democratic effect is no longer significant, as it would seem that it's contribution was more due to it's correlation with life expectancy. But the key question is- is this model better?  \n",
    "\n",
    "The adjusted $R^2$ seems to indicate that we are doing slightly better with this model, but not by much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ANOVA, or analysis of variance test, is essentially comparing whether the residual sum of squares (i.e. the loss) is statistically less for one model vs. the other. In many settings it is often called a *likelihood ratio test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42.78224346440508, 5.128069116262817e-10, 2.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chi.square statistic, p-value, df\n",
    "happy_model_more.compare_lm_test(happy_model_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " An approach that works in many settings is to compare *AIC* (Akaike Information Criterion). AIC is a value based on the likelihood for a given model, but which adds a penalty for complexity, since otherwise any more complex model would result in a larger likelihood (or in this case, smaller negative likelihood).  In the following, $\\mathcal{L}$ is the likelihood, and $\\mathcal{P}$ is the number of parameters estimated for the model.\n",
    "\n",
    "$$AIC = -2 ( \\ln (\\mathcal{L})) + 2 \\mathcal{P}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[686.6589001213847, 645.4697022542996]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[happy_model_base.aic, happy_model_more.aic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our new model works better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Interactions\n",
    "\n",
    "Let's now add interactions to our model.  Interactions allow the relationship of a predictor variable and target to vary depending on the values of another covariate.  To keep things simple, we'll add a single interaction to start- I will interact democratic quality with life expectancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>happiness_score</td> <th>  R-squared:         </th> <td>   0.736</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.733</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   224.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 25 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>4.32e-114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:33:07</td>     <th>  Log-Likelihood:    </th> <td> -310.01</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   409</td>      <th>  AIC:               </th> <td>   632.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   403</td>      <th>  BIC:               </th> <td>   656.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                           <td></td>                              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                           <td>   -3.6670</td> <td>    0.384</td> <td>   -9.555</td> <td> 0.000</td> <td>   -4.421</td> <td>   -2.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>democratic_quality</th>                                  <td>    0.0277</td> <td>    0.036</td> <td>    0.761</td> <td> 0.447</td> <td>   -0.044</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>generosity</th>                                          <td>    0.1417</td> <td>    0.027</td> <td>    5.199</td> <td> 0.000</td> <td>    0.088</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_gdp_per_capita</th>                                  <td>    0.3812</td> <td>    0.042</td> <td>    9.081</td> <td> 0.000</td> <td>    0.299</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>healthy_life_expectancy_at_birth</th>                    <td>    0.4170</td> <td>    0.056</td> <td>    7.435</td> <td> 0.000</td> <td>    0.307</td> <td>    0.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>democratic_quality:healthy_life_expectancy_at_birth</th> <td>    0.1184</td> <td>    0.032</td> <td>    3.687</td> <td> 0.000</td> <td>    0.055</td> <td>    0.182</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.513</td> <th>  Durbin-Watson:     </th> <td>   0.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.173</td> <th>  Jarque-Bera (JB):  </th> <td>   2.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.075</td> <th>  Prob(JB):          </th> <td>   0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.625</td> <th>  Cond. No.          </th> <td>    143.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        happiness_score   R-squared:                       0.736\n",
       "Model:                            OLS   Adj. R-squared:                  0.733\n",
       "Method:                 Least Squares   F-statistic:                     224.5\n",
       "Date:                Tue, 25 Feb 2020   Prob (F-statistic):          4.32e-114\n",
       "Time:                        14:33:07   Log-Likelihood:                -310.01\n",
       "No. Observations:                 409   AIC:                             632.0\n",
       "Df Residuals:                     403   BIC:                             656.1\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=======================================================================================================================\n",
       "                                                          coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                              -3.6670      0.384     -9.555      0.000      -4.421      -2.913\n",
       "democratic_quality                                      0.0277      0.036      0.761      0.447      -0.044       0.099\n",
       "generosity                                              0.1417      0.027      5.199      0.000       0.088       0.195\n",
       "log_gdp_per_capita                                      0.3812      0.042      9.081      0.000       0.299       0.464\n",
       "healthy_life_expectancy_at_birth                        0.4170      0.056      7.435      0.000       0.307       0.527\n",
       "democratic_quality:healthy_life_expectancy_at_birth     0.1184      0.032      3.687      0.000       0.055       0.182\n",
       "==============================================================================\n",
       "Omnibus:                        3.513   Durbin-Watson:                   0.859\n",
       "Prob(Omnibus):                  0.173   Jarque-Bera (JB):                2.780\n",
       "Skew:                           0.075   Prob(JB):                        0.249\n",
       "Kurtosis:                       2.625   Cond. No.                         143.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_model_more = smf.ols(\n",
    "  'happiness_score ~ democratic_quality + generosity + log_gdp_per_capita + healthy_life_expectancy_at_birth + democratic_quality:healthy_life_expectancy_at_birth',\n",
    "  data = happy_processed\n",
    ").fit()\n",
    "\n",
    "happy_model_more.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient interpretation for variables in the interaction model changes.  For those involved in an interaction, the base coefficient now only describes the effect when the variable they interact with is zero (or is at the reference group if it's categorical). So democratic quality has a slight positive but not statistically notable effect at the mean of life expectancy.\n",
    "\n",
    "However, this effect increases when life expectancy increases by 1 (i.e. 1 standard deviation).  The same interpretation goes for life expectancy.  It's base coefficient is when democratic quality is at it's mean, and the interaction term is interpreted identically."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
